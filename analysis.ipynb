{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data from: https://www.kaggle.com/yuanyuwendymu/airline-delay-and-cancellation-data-2009-2018?rvi=1\n",
    "\n",
    "df16 = pd.read_csv('2016.csv')\n",
    "df17 = pd.read_csv('2017.csv')\n",
    "df18 = pd.read_csv('2018.csv')\n",
    "\n",
    "# data from: https://www.kaggle.com/sobhanmoosavi/us-weather-events\n",
    "df_weather = pd.read_csv('US_WeatherEvents_2016-2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df16, df17, df18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18505725, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EventId</th>\n",
       "      <th>Type</th>\n",
       "      <th>Severity</th>\n",
       "      <th>StartTime(UTC)</th>\n",
       "      <th>EndTime(UTC)</th>\n",
       "      <th>TimeZone</th>\n",
       "      <th>AirportCode</th>\n",
       "      <th>LocationLat</th>\n",
       "      <th>LocationLng</th>\n",
       "      <th>City</th>\n",
       "      <th>County</th>\n",
       "      <th>State</th>\n",
       "      <th>ZipCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>W-1</td>\n",
       "      <td>Snow</td>\n",
       "      <td>Light</td>\n",
       "      <td>2016-01-06 23:14:00</td>\n",
       "      <td>2016-01-07 00:34:00</td>\n",
       "      <td>US/Mountain</td>\n",
       "      <td>K04V</td>\n",
       "      <td>38.0972</td>\n",
       "      <td>-106.1689</td>\n",
       "      <td>Saguache</td>\n",
       "      <td>Saguache</td>\n",
       "      <td>CO</td>\n",
       "      <td>81149.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>W-2</td>\n",
       "      <td>Snow</td>\n",
       "      <td>Light</td>\n",
       "      <td>2016-01-07 04:14:00</td>\n",
       "      <td>2016-01-07 04:54:00</td>\n",
       "      <td>US/Mountain</td>\n",
       "      <td>K04V</td>\n",
       "      <td>38.0972</td>\n",
       "      <td>-106.1689</td>\n",
       "      <td>Saguache</td>\n",
       "      <td>Saguache</td>\n",
       "      <td>CO</td>\n",
       "      <td>81149.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>W-3</td>\n",
       "      <td>Snow</td>\n",
       "      <td>Light</td>\n",
       "      <td>2016-01-07 05:54:00</td>\n",
       "      <td>2016-01-07 15:34:00</td>\n",
       "      <td>US/Mountain</td>\n",
       "      <td>K04V</td>\n",
       "      <td>38.0972</td>\n",
       "      <td>-106.1689</td>\n",
       "      <td>Saguache</td>\n",
       "      <td>Saguache</td>\n",
       "      <td>CO</td>\n",
       "      <td>81149.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>W-4</td>\n",
       "      <td>Snow</td>\n",
       "      <td>Light</td>\n",
       "      <td>2016-01-08 05:34:00</td>\n",
       "      <td>2016-01-08 05:54:00</td>\n",
       "      <td>US/Mountain</td>\n",
       "      <td>K04V</td>\n",
       "      <td>38.0972</td>\n",
       "      <td>-106.1689</td>\n",
       "      <td>Saguache</td>\n",
       "      <td>Saguache</td>\n",
       "      <td>CO</td>\n",
       "      <td>81149.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>W-5</td>\n",
       "      <td>Snow</td>\n",
       "      <td>Light</td>\n",
       "      <td>2016-01-08 13:54:00</td>\n",
       "      <td>2016-01-08 15:54:00</td>\n",
       "      <td>US/Mountain</td>\n",
       "      <td>K04V</td>\n",
       "      <td>38.0972</td>\n",
       "      <td>-106.1689</td>\n",
       "      <td>Saguache</td>\n",
       "      <td>Saguache</td>\n",
       "      <td>CO</td>\n",
       "      <td>81149.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>W-6</td>\n",
       "      <td>Snow</td>\n",
       "      <td>Light</td>\n",
       "      <td>2016-01-08 16:14:00</td>\n",
       "      <td>2016-01-08 17:34:00</td>\n",
       "      <td>US/Mountain</td>\n",
       "      <td>K04V</td>\n",
       "      <td>38.0972</td>\n",
       "      <td>-106.1689</td>\n",
       "      <td>Saguache</td>\n",
       "      <td>Saguache</td>\n",
       "      <td>CO</td>\n",
       "      <td>81149.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>W-7</td>\n",
       "      <td>Fog</td>\n",
       "      <td>Severe</td>\n",
       "      <td>2016-01-09 12:54:00</td>\n",
       "      <td>2016-01-09 15:34:00</td>\n",
       "      <td>US/Mountain</td>\n",
       "      <td>K04V</td>\n",
       "      <td>38.0972</td>\n",
       "      <td>-106.1689</td>\n",
       "      <td>Saguache</td>\n",
       "      <td>Saguache</td>\n",
       "      <td>CO</td>\n",
       "      <td>81149.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>W-8</td>\n",
       "      <td>Snow</td>\n",
       "      <td>Light</td>\n",
       "      <td>2016-01-09 15:34:00</td>\n",
       "      <td>2016-01-09 16:14:00</td>\n",
       "      <td>US/Mountain</td>\n",
       "      <td>K04V</td>\n",
       "      <td>38.0972</td>\n",
       "      <td>-106.1689</td>\n",
       "      <td>Saguache</td>\n",
       "      <td>Saguache</td>\n",
       "      <td>CO</td>\n",
       "      <td>81149.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>W-9</td>\n",
       "      <td>Fog</td>\n",
       "      <td>Severe</td>\n",
       "      <td>2016-01-09 16:14:00</td>\n",
       "      <td>2016-01-09 16:34:00</td>\n",
       "      <td>US/Mountain</td>\n",
       "      <td>K04V</td>\n",
       "      <td>38.0972</td>\n",
       "      <td>-106.1689</td>\n",
       "      <td>Saguache</td>\n",
       "      <td>Saguache</td>\n",
       "      <td>CO</td>\n",
       "      <td>81149.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>W-10</td>\n",
       "      <td>Snow</td>\n",
       "      <td>Light</td>\n",
       "      <td>2016-01-09 16:34:00</td>\n",
       "      <td>2016-01-09 16:54:00</td>\n",
       "      <td>US/Mountain</td>\n",
       "      <td>K04V</td>\n",
       "      <td>38.0972</td>\n",
       "      <td>-106.1689</td>\n",
       "      <td>Saguache</td>\n",
       "      <td>Saguache</td>\n",
       "      <td>CO</td>\n",
       "      <td>81149.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  EventId  Type Severity       StartTime(UTC)         EndTime(UTC)  \\\n",
       "0     W-1  Snow    Light  2016-01-06 23:14:00  2016-01-07 00:34:00   \n",
       "1     W-2  Snow    Light  2016-01-07 04:14:00  2016-01-07 04:54:00   \n",
       "2     W-3  Snow    Light  2016-01-07 05:54:00  2016-01-07 15:34:00   \n",
       "3     W-4  Snow    Light  2016-01-08 05:34:00  2016-01-08 05:54:00   \n",
       "4     W-5  Snow    Light  2016-01-08 13:54:00  2016-01-08 15:54:00   \n",
       "5     W-6  Snow    Light  2016-01-08 16:14:00  2016-01-08 17:34:00   \n",
       "6     W-7   Fog   Severe  2016-01-09 12:54:00  2016-01-09 15:34:00   \n",
       "7     W-8  Snow    Light  2016-01-09 15:34:00  2016-01-09 16:14:00   \n",
       "8     W-9   Fog   Severe  2016-01-09 16:14:00  2016-01-09 16:34:00   \n",
       "9    W-10  Snow    Light  2016-01-09 16:34:00  2016-01-09 16:54:00   \n",
       "\n",
       "      TimeZone AirportCode  LocationLat  LocationLng      City    County  \\\n",
       "0  US/Mountain        K04V      38.0972    -106.1689  Saguache  Saguache   \n",
       "1  US/Mountain        K04V      38.0972    -106.1689  Saguache  Saguache   \n",
       "2  US/Mountain        K04V      38.0972    -106.1689  Saguache  Saguache   \n",
       "3  US/Mountain        K04V      38.0972    -106.1689  Saguache  Saguache   \n",
       "4  US/Mountain        K04V      38.0972    -106.1689  Saguache  Saguache   \n",
       "5  US/Mountain        K04V      38.0972    -106.1689  Saguache  Saguache   \n",
       "6  US/Mountain        K04V      38.0972    -106.1689  Saguache  Saguache   \n",
       "7  US/Mountain        K04V      38.0972    -106.1689  Saguache  Saguache   \n",
       "8  US/Mountain        K04V      38.0972    -106.1689  Saguache  Saguache   \n",
       "9  US/Mountain        K04V      38.0972    -106.1689  Saguache  Saguache   \n",
       "\n",
       "  State  ZipCode  \n",
       "0    CO  81149.0  \n",
       "1    CO  81149.0  \n",
       "2    CO  81149.0  \n",
       "3    CO  81149.0  \n",
       "4    CO  81149.0  \n",
       "5    CO  81149.0  \n",
       "6    CO  81149.0  \n",
       "7    CO  81149.0  \n",
       "8    CO  81149.0  \n",
       "9    CO  81149.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weather.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting date format\n",
    "df[\"date\"] = pd.to_datetime(df[\"FL_DATE\"]).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather[\"date\"] = pd.to_datetime(df_weather[\"StartTime(UTC)\"]).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['FL_DATE', 'OP_CARRIER', 'OP_CARRIER_FL_NUM', 'ORIGIN', 'DEST',\n",
       "       'CRS_DEP_TIME', 'DEP_TIME', 'DEP_DELAY', 'TAXI_OUT', 'WHEELS_OFF',\n",
       "       'WHEELS_ON', 'TAXI_IN', 'CRS_ARR_TIME', 'ARR_TIME', 'ARR_DELAY',\n",
       "       'CANCELLED', 'CANCELLATION_CODE', 'DIVERTED', 'CRS_ELAPSED_TIME',\n",
       "       'ACTUAL_ELAPSED_TIME', 'AIR_TIME', 'DISTANCE', 'CARRIER_DELAY',\n",
       "       'WEATHER_DELAY', 'NAS_DELAY', 'SECURITY_DELAY', 'LATE_AIRCRAFT_DELAY',\n",
       "       'Unnamed: 27', 'date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting airport code format in weather dataset\n",
    "def convert_arpt_code(code):\n",
    "    new_code = code[1:]\n",
    "    return new_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather['Airport'] = df_weather['AirportCode'].apply(convert_arpt_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather_dropped = df_weather.drop(columns = ['EventId','EndTime(UTC)','TimeZone','LocationLat','LocationLng','City','County','State','ZipCode','StartTime(UTC)','AirportCode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Severity</th>\n",
       "      <th>date</th>\n",
       "      <th>Airport</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Snow</td>\n",
       "      <td>Light</td>\n",
       "      <td>2016-01-06</td>\n",
       "      <td>04V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Snow</td>\n",
       "      <td>Light</td>\n",
       "      <td>2016-01-07</td>\n",
       "      <td>04V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Snow</td>\n",
       "      <td>Light</td>\n",
       "      <td>2016-01-07</td>\n",
       "      <td>04V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Snow</td>\n",
       "      <td>Light</td>\n",
       "      <td>2016-01-08</td>\n",
       "      <td>04V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Snow</td>\n",
       "      <td>Light</td>\n",
       "      <td>2016-01-08</td>\n",
       "      <td>04V</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Type Severity        date Airport\n",
       "0  Snow    Light  2016-01-06     04V\n",
       "1  Snow    Light  2016-01-07     04V\n",
       "2  Snow    Light  2016-01-07     04V\n",
       "3  Snow    Light  2016-01-08     04V\n",
       "4  Snow    Light  2016-01-08     04V"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weather_dropped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the format of the weather dataset\n",
    "#so that it can be merged with the flights dataset\n",
    "df_weather_dumb = pd.get_dummies(data = df_weather_dropped, columns=['Type', 'Severity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather_dumb_1 = df_weather_dumb.groupby([\"date\", \"Airport\"], as_index = False).aggregate(\"sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combine_1 = df.merge(df_weather_dumb_1, left_on=['ORIGIN', 'date'], right_on=['Airport', 'date'], left_index = True, how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['FL_DATE', 'OP_CARRIER', 'OP_CARRIER_FL_NUM', 'ORIGIN', 'DEST',\n",
       "       'CRS_DEP_TIME', 'DEP_TIME', 'DEP_DELAY', 'TAXI_OUT', 'WHEELS_OFF',\n",
       "       'WHEELS_ON', 'TAXI_IN', 'CRS_ARR_TIME', 'ARR_TIME', 'ARR_DELAY',\n",
       "       'CANCELLED', 'CANCELLATION_CODE', 'DIVERTED', 'CRS_ELAPSED_TIME',\n",
       "       'ACTUAL_ELAPSED_TIME', 'AIR_TIME', 'DISTANCE', 'CARRIER_DELAY',\n",
       "       'WEATHER_DELAY', 'NAS_DELAY', 'SECURITY_DELAY', 'LATE_AIRCRAFT_DELAY',\n",
       "       'Unnamed: 27', 'date', 'Airport', 'Type_Cold', 'Type_Fog', 'Type_Hail',\n",
       "       'Type_Precipitation', 'Type_Rain', 'Type_Snow', 'Type_Storm',\n",
       "       'Severity_Heavy', 'Severity_Light', 'Severity_Moderate',\n",
       "       'Severity_Other', 'Severity_Severe', 'Severity_UNK'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combine_1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping unused columns\n",
    "df_combine_drop = df_combine_1.drop(columns = ['FL_DATE', \n",
    "       'DEP_TIME', 'TAXI_OUT', 'WHEELS_OFF',\n",
    "       'WHEELS_ON', 'TAXI_IN', 'ARR_TIME', 'ARR_DELAY',\n",
    "       'CANCELLATION_CODE', 'DIVERTED', \n",
    "       'ACTUAL_ELAPSED_TIME', 'AIR_TIME', 'CARRIER_DELAY',\n",
    "       'WEATHER_DELAY', 'NAS_DELAY', 'SECURITY_DELAY', 'LATE_AIRCRAFT_DELAY',\n",
    "       'Unnamed: 27', 'Airport'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns & join the two datasets again\n",
    "#on Destination airport\n",
    "df_combine_drop.rename(columns={'Type_Cold': 1, 'Type_Fog': 2, 'Type_Hail': 3,\n",
    "       'Type_Precipitation': 4, 'Type_Rain': 5, 'Type_Snow': 6, 'Type_Storm': 7,\n",
    "       'Severity_Heavy': 8, 'Severity_Light': 9, 'Severity_Moderate': 10,\n",
    "       'Severity_Other': 11, 'Severity_Severe': 12, 'Severity_UNK': 13}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combine_new = df_combine_drop.merge(df_weather_dumb_1, left_on=['DEST', 'date'], right_on=['Airport', 'date'], left_index = True, how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combine_new.rename(columns={'Type_Cold': 14, 'Type_Fog': 15, 'Type_Hail': 16,\n",
    "       'Type_Precipitation': 17, 'Type_Rain': 18, 'Type_Snow': 19, 'Type_Storm': 20,\n",
    "       'Severity_Heavy': 21, 'Severity_Light': 22, 'Severity_Moderate': 23,\n",
    "       'Severity_Other': 24, 'Severity_Severe': 25, 'Severity_UNK': 26}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18505725, 38)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combine_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2a. feature engineering (cancellation model, no weather)\n",
    "(After experimenting with the datasets, we found that appending the weather dataset does not improve model performance. Thus, the subsequent code only uses the original dataset containing flight information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cancelled = df[df['CANCELLED'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(265138, 29)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cancelled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_not_cancelled = df[df['CANCELLED'] == 0]\n",
    "df_normal = df_not_cancelled.sample(265000)\n",
    "df_cancel_model = pd.concat([df_cancelled, df_normal])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(530138, 29)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cancel_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cancel_model.drop(columns=['FL_DATE', \n",
    "       'DEP_TIME', 'TAXI_OUT', 'WHEELS_OFF',\n",
    "       'WHEELS_ON', 'TAXI_IN', 'ARR_TIME', 'ARR_DELAY',\n",
    "       'CANCELLATION_CODE', 'DIVERTED', \n",
    "       'ACTUAL_ELAPSED_TIME', 'AIR_TIME', 'CARRIER_DELAY',\n",
    "       'WEATHER_DELAY', 'NAS_DELAY', 'SECURITY_DELAY', 'LATE_AIRCRAFT_DELAY',\n",
    "       'Unnamed: 27', 'DEP_DELAY'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OP_CARRIER</th>\n",
       "      <th>OP_CARRIER_FL_NUM</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>DEST</th>\n",
       "      <th>CRS_DEP_TIME</th>\n",
       "      <th>CRS_ARR_TIME</th>\n",
       "      <th>CANCELLED</th>\n",
       "      <th>CRS_ELAPSED_TIME</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>AS</td>\n",
       "      <td>29</td>\n",
       "      <td>ORD</td>\n",
       "      <td>SEA</td>\n",
       "      <td>1530</td>\n",
       "      <td>1815</td>\n",
       "      <td>1.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>1721.0</td>\n",
       "      <td>2016-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>AS</td>\n",
       "      <td>40</td>\n",
       "      <td>ADQ</td>\n",
       "      <td>ANC</td>\n",
       "      <td>1720</td>\n",
       "      <td>1809</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>2016-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>AS</td>\n",
       "      <td>49</td>\n",
       "      <td>ANC</td>\n",
       "      <td>ADQ</td>\n",
       "      <td>1530</td>\n",
       "      <td>1628</td>\n",
       "      <td>1.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>2016-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>EV</td>\n",
       "      <td>3274</td>\n",
       "      <td>ERI</td>\n",
       "      <td>ORD</td>\n",
       "      <td>1655</td>\n",
       "      <td>1739</td>\n",
       "      <td>1.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>398.0</td>\n",
       "      <td>2016-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242</th>\n",
       "      <td>EV</td>\n",
       "      <td>3815</td>\n",
       "      <td>IAH</td>\n",
       "      <td>OKC</td>\n",
       "      <td>1445</td>\n",
       "      <td>1615</td>\n",
       "      <td>1.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>395.0</td>\n",
       "      <td>2016-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     OP_CARRIER  OP_CARRIER_FL_NUM ORIGIN DEST  CRS_DEP_TIME  CRS_ARR_TIME  \\\n",
       "699          AS                 29    ORD  SEA          1530          1815   \n",
       "710          AS                 40    ADQ  ANC          1720          1809   \n",
       "713          AS                 49    ANC  ADQ          1530          1628   \n",
       "1231         EV               3274    ERI  ORD          1655          1739   \n",
       "1242         EV               3815    IAH  OKC          1445          1615   \n",
       "\n",
       "      CANCELLED  CRS_ELAPSED_TIME  DISTANCE        date  \n",
       "699         1.0             285.0    1721.0  2016-01-01  \n",
       "710         1.0              49.0     253.0  2016-01-01  \n",
       "713         1.0              58.0     253.0  2016-01-01  \n",
       "1231        1.0             104.0     398.0  2016-01-01  \n",
       "1242        1.0              90.0     395.0  2016-01-01  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cancel_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OP_CARRIER            0\n",
       "OP_CARRIER_FL_NUM     0\n",
       "ORIGIN                0\n",
       "DEST                  0\n",
       "CRS_DEP_TIME          0\n",
       "CRS_ARR_TIME          0\n",
       "CANCELLED             0\n",
       "CRS_ELAPSED_TIME     16\n",
       "DISTANCE              0\n",
       "date                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cancel_model.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cancel_model = df_cancel_model.dropna(subset = [\"CRS_ELAPSED_TIME\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cancel_model['month'] = pd.to_datetime(df_cancel_model[\"date\"]).dt.month\n",
    "df_cancel_model['day'] = pd.to_datetime(df_cancel_model[\"date\"]).dt.day\n",
    "df_cancel_model['day_of_week'] = pd.to_datetime(df_cancel_model[\"date\"]).dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cancel_model['AIRLINE'] = le.fit_transform(df_cancel_model['OP_CARRIER'])\n",
    "df_cancel_model['dest'] = le.fit_transform(df_cancel_model['DEST'])\n",
    "df_cancel_model['origin'] = le.fit_transform(df_cancel_model['ORIGIN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cancel_model.drop(columns = ['date', 'DEST', 'ORIGIN', 'OP_CARRIER'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3a. model training and prediction (cancellation model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_cancel_model['CANCELLED']\n",
    "X = df_cancel_model.drop(columns = ['CANCELLED'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_cancel_model, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(424097, 12)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106025, 12)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=0,solver='lbfgs',n_jobs=-1,verbose=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n",
      "Memmapping (shape=(424097, 12), dtype=float64) to new file /dev/shm/joblib_memmapping_folder_65789_9044805346/65789-140019227758776-9b2bb235df5347fa853e361bf4342078.pkl\n",
      "Memmapping (shape=(424097,), dtype=float64) to new file /dev/shm/joblib_memmapping_folder_65789_9044805346/65789-140019227758776-dd4286b1afb9414bbbf19385b58609f0.pkl\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   36.8s\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:   36.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn', n_jobs=-1,\n",
       "          penalty='l2', random_state=0, solver='lbfgs', tol=0.0001,\n",
       "          verbose=100, warm_start=False)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6012449893892949"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = clf.predict(X_test)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(random_state=0,n_estimators=10,max_depth=10,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = rf_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rf_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using 10-fold cross validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(clf, X, y, cv=10, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2b. feature engineering (delay model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_delay_model = df_combine_new.dropna(subset = [\"DEP_DELAY\", \"CRS_ELAPSED_TIME\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/pandas/core/frame.py:4034: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  downcast=downcast, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "df_delay_model.fillna(0.0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OP_CARRIER           0\n",
       "OP_CARRIER_FL_NUM    0\n",
       "ORIGIN               0\n",
       "DEST                 0\n",
       "CRS_DEP_TIME         0\n",
       "DEP_DELAY            0\n",
       "CRS_ARR_TIME         0\n",
       "CANCELLED            0\n",
       "CRS_ELAPSED_TIME     0\n",
       "DISTANCE             0\n",
       "date                 0\n",
       "1                    0\n",
       "2                    0\n",
       "3                    0\n",
       "4                    0\n",
       "5                    0\n",
       "6                    0\n",
       "7                    0\n",
       "8                    0\n",
       "9                    0\n",
       "10                   0\n",
       "11                   0\n",
       "12                   0\n",
       "13                   0\n",
       "Airport              0\n",
       "14                   0\n",
       "15                   0\n",
       "16                   0\n",
       "17                   0\n",
       "18                   0\n",
       "19                   0\n",
       "20                   0\n",
       "21                   0\n",
       "22                   0\n",
       "23                   0\n",
       "24                   0\n",
       "25                   0\n",
       "26                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_delay_model.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "df_delay_model['month'] = pd.to_datetime(df_delay_model[\"date\"]).dt.month\n",
    "df_delay_model['day'] = pd.to_datetime(df_delay_model[\"date\"]).dt.day\n",
    "df_delay_model['day_of_week'] = pd.to_datetime(df_delay_model[\"date\"]).dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "df_delay_model['AIRLINE'] = le.fit_transform(df_delay_model['OP_CARRIER'])\n",
    "df_delay_model['dest'] = le.fit_transform(df_delay_model['DEST'])\n",
    "df_delay_model['origin'] = le.fit_transform(df_delay_model['ORIGIN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/pandas/core/frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "df_delay_model.drop(columns = ['date', 'DEST', 'ORIGIN', 'OP_CARRIER', 'Airport'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18244669, 39)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_delay_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_delay_model.drop(columns=['CANCELLED'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(row):\n",
    "    if row['DEP_DELAY'] <= 0:\n",
    "        val = 0\n",
    "    elif row['DEP_DELAY'] <= 15 and row['DEP_DELAY'] > 0:\n",
    "        val = 1\n",
    "    elif row['DEP_DELAY'] <= 30 and row['DEP_DELAY'] > 15:\n",
    "        val = 2\n",
    "    else:\n",
    "        val = 3\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_delay_model['DEPARTURE_DELAY_t'] = df_delay_model.apply(f, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2041629, 39)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_delay_model[df_delay_model['DEPARTURE_DELAY_t'] == 3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0 = df_delay_model[df_delay_model['DEPARTURE_DELAY_t'] == 0]\n",
    "de_not_0 = df_delay_model[df_delay_model['DEPARTURE_DELAY_t'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0_new = df_0.sample(1100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.concat([df_0_new, de_not_0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3b. model training and prediction (delay model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_delay_model['DEPARTURE_DELAY_t']\n",
    "X = df_delay_model.drop(columns = ['DEP_DELAY', 'DEPARTURE_DELAY_t'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14595735, 37)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n",
      "Memmapping (shape=(14595735, 37), dtype=float64) to new file /dev/shm/joblib_memmapping_folder_65789_5205661408/65789-140019227614568-ea02dce732ce43dbb89eb7a3bf821ddb.pkl\n",
      "Memmapping (shape=(14595735,), dtype=int64) to new file /dev/shm/joblib_memmapping_folder_65789_5205661408/65789-140019227614568-6d20e8c9ad1b4f94a97aae1539bdf51b.pkl\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed: 21.0min\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed: 21.0min finished\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0,solver='lbfgs',n_jobs = -1,verbose = 100).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6571624128195726"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 96 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 100\n",
      "building tree 2 of 100\n",
      "building tree 3 of 100\n",
      "building tree 4 of 100\n",
      "building tree 5 of 100\n",
      "building tree 6 of 100\n",
      "building tree 7 of 100\n",
      "building tree 8 of 100\n",
      "building tree 9 of 100\n",
      "building tree 10 of 100\n",
      "building tree 11 of 100\n",
      "building tree 12 of 100\n",
      "building tree 13 of 100\n",
      "building tree 14 of 100\n",
      "building tree 15 of 100\n",
      "building tree 16 of 100\n",
      "building tree 17 of 100\n",
      "building tree 18 of 100\n",
      "building tree 19 of 100\n",
      "building tree 20 of 100\n",
      "building tree 21 of 100\n",
      "building tree 22 of 100\n",
      "building tree 23 of 100\n",
      "building tree 24 of 100\n",
      "building tree 25 of 100\n",
      "building tree 26 of 100\n",
      "building tree 27 of 100\n",
      "building tree 28 of 100\n",
      "building tree 29 of 100\n",
      "building tree 30 of 100\n",
      "building tree 31 of 100\n",
      "building tree 32 of 100\n",
      "building tree 33 of 100\n",
      "building tree 34 of 100\n",
      "building tree 35 of 100\n",
      "building tree 36 of 100\n",
      "building tree 37 of 100building tree 38 of 100building tree 39 of 100\n",
      "building tree 40 of 100\n",
      "building tree 41 of 100\n",
      "building tree 42 of 100\n",
      "building tree 43 of 100\n",
      "building tree 44 of 100building tree 45 of 100\n",
      "building tree 46 of 100\n",
      "building tree 47 of 100\n",
      "\n",
      "building tree 48 of 100\n",
      "building tree 49 of 100\n",
      "building tree 50 of 100\n",
      "building tree 51 of 100\n",
      "building tree 52 of 100\n",
      "building tree 53 of 100\n",
      "building tree 54 of 100\n",
      "building tree 55 of 100\n",
      "building tree 56 of 100\n",
      "building tree 57 of 100\n",
      "building tree 58 of 100\n",
      "building tree 59 of 100\n",
      "building tree 60 of 100\n",
      "building tree 61 of 100\n",
      "building tree 62 of 100\n",
      "building tree 63 of 100\n",
      "building tree 64 of 100\n",
      "building tree 65 of 100building tree 66 of 100\n",
      "building tree 67 of 100\n",
      "building tree 68 of 100\n",
      "building tree 69 of 100\n",
      "building tree 70 of 100\n",
      "building tree 71 of 100\n",
      "building tree 72 of 100\n",
      "building tree 73 of 100\n",
      "building tree 74 of 100\n",
      "building tree 75 of 100\n",
      "building tree 76 of 100\n",
      "\n",
      "building tree 77 of 100\n",
      "building tree 78 of 100\n",
      "building tree 79 of 100\n",
      "building tree 80 of 100\n",
      "building tree 81 of 100\n",
      "building tree 82 of 100\n",
      "building tree 83 of 100\n",
      "building tree 84 of 100\n",
      "building tree 85 of 100\n",
      "building tree 86 of 100\n",
      "building tree 87 of 100\n",
      "building tree 88 of 100\n",
      "\n",
      "building tree 89 of 100\n",
      "building tree 90 of 100\n",
      "\n",
      "building tree 91 of 100\n",
      "building tree 92 of 100\n",
      "building tree 93 of 100\n",
      "building tree 94 of 100\n",
      "building tree 95 of 100\n",
      "building tree 96 of 100\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(random_state=0,n_estimators = 100,n_jobs = -1, verbose = 10)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done   8 out of 100 | elapsed:   14.9s remaining:  2.9min\n",
      "[Parallel(n_jobs=96)]: Done  19 out of 100 | elapsed:   15.1s remaining:  1.1min\n",
      "[Parallel(n_jobs=96)]: Done  30 out of 100 | elapsed:   15.4s remaining:   35.8s\n",
      "[Parallel(n_jobs=96)]: Done  41 out of 100 | elapsed:   16.4s remaining:   23.5s\n",
      "[Parallel(n_jobs=96)]: Done  52 out of 100 | elapsed:   18.9s remaining:   17.5s\n",
      "[Parallel(n_jobs=96)]: Done  63 out of 100 | elapsed:   20.8s remaining:   12.2s\n",
      "[Parallel(n_jobs=96)]: Done  74 out of 100 | elapsed:   22.1s remaining:    7.8s\n",
      "[Parallel(n_jobs=96)]: Done  85 out of 100 | elapsed:   24.1s remaining:    4.3s\n",
      "[Parallel(n_jobs=96)]: Done  96 out of 100 | elapsed:   25.1s remaining:    1.0s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:   27.1s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done   8 out of 100 | elapsed:   10.7s remaining:  2.0min\n",
      "[Parallel(n_jobs=96)]: Done  19 out of 100 | elapsed:   10.9s remaining:   46.3s\n",
      "[Parallel(n_jobs=96)]: Done  30 out of 100 | elapsed:   11.0s remaining:   25.8s\n",
      "[Parallel(n_jobs=96)]: Done  41 out of 100 | elapsed:   11.2s remaining:   16.1s\n",
      "[Parallel(n_jobs=96)]: Done  52 out of 100 | elapsed:   11.4s remaining:   10.5s\n",
      "[Parallel(n_jobs=96)]: Done  63 out of 100 | elapsed:   11.5s remaining:    6.8s\n",
      "[Parallel(n_jobs=96)]: Done  74 out of 100 | elapsed:   11.7s remaining:    4.1s\n",
      "[Parallel(n_jobs=96)]: Done  85 out of 100 | elapsed:   11.9s remaining:    2.1s\n",
      "[Parallel(n_jobs=96)]: Done  96 out of 100 | elapsed:   15.8s remaining:    0.7s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:   17.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7064589274566215"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = clf.predict(X_test)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using 10-fold cross validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(clf, X, y, cv=5, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
